{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TITANIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib.pyplot'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-47aae6484d1b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib.pyplot'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import linear_model\n",
    "from sklearn.cluster import KMeans\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "pred_aceptable = np.vectorize(lambda x: int(round(x-x)) if x<0.5 else int(round(x+(1-x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "test_original = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Division en TRAIN = X_train y VALIDATION = X_test\n",
    "X = df.drop(['Survived','PassengerId'], axis=1)\n",
    "\n",
    "y = df['Survived']\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=382)\n",
    "\n",
    "print(X_train.shape[0], X_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analisis de variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cabin - se elimina porque tiene mas nulos que variables completas\n",
    "X_train.drop(['Cabin'], axis=1,inplace=True)\n",
    "\n",
    "X_test.drop(['Cabin'], axis=1,inplace=True)\n",
    "\n",
    "test_original.drop(['Cabin'], axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Age is an important factor in the survival, what we can deduce from these is that:\n",
    "- Age is between 0 and 10 from any class you are likely to survived\n",
    "- > 10 the number of children increses for clases 2 and 3, and they survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Age - Sex vs Survived\n",
    "f,ax=plt.subplots(1,2,figsize=(18,8))\n",
    "sb.violinplot('Pclass','Age',hue='Survived',data=df,split=True,ax=ax[0])\n",
    "ax[0].set_title('PClass and Age vs Survived')\n",
    "ax[0].set_yticks(range(0,110,5))\n",
    "sb.violinplot(\"Sex\",\"Age\", hue=\"Survived\", data=df,split=True,ax=ax[1])\n",
    "ax[1].set_title('Sex and Age vs Survived')\n",
    "ax[1].set_yticks(range(0,110,5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Text analisis of variable name to impute mean age\n",
    "X_train['Initial']=0\n",
    "for i in X_train:\n",
    "    X_train['Initial']=X_train.Name.str.extract('([A-Za-z]+)\\.') #extracting Name initials\n",
    "\n",
    "pd.crosstab(X_train.Initial,X_train.Sex).T.style.background_gradient(cmap='summer_r')\n",
    "\n",
    "X_train['Initial'].replace(['Mlle','Mme','Ms','Dr','Major','Lady','Countess',\\\n",
    "                        'Jonkheer','Col','Rev','Capt','Sir','Don'],['Miss',\\\n",
    "                        'Miss','Miss','Mr','Mr','Mrs','Mrs','Other','Other','Other','Mr','Mr','Mr'],inplace=True)\n",
    "\n",
    "X_train.groupby('Initial')['Age'].mean()\n",
    "\n",
    "X_train.loc[(X_train.Age.isnull()) & (X_train.Initial=='Mr'),'Age']= 33\n",
    "X_train.loc[(X_train.Age.isnull()) & (X_train.Initial=='Mrs'),'Age']=36\n",
    "X_train.loc[(X_train.Age.isnull()) & (X_train.Initial=='Master'),'Age']=5\n",
    "X_train.loc[(X_train.Age.isnull()) & (X_train.Initial=='Miss'),'Age']=22\n",
    "X_train.loc[(X_train.Age.isnull()) & (X_train.Initial=='Other'),'Age']=46\n",
    "\n",
    "X_train.Age.isnull().any()\n",
    "\n",
    "#Se elimina la variable Initial, ya que se genero solo para el calculo\n",
    "X_train.drop(['Initial'], axis=1,inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se repite lo mismo para TEST y Validation\n",
    "X_test['Initial']=0\n",
    "for i in X_test:\n",
    "    X_test['Initial']=X_test.Name.str.extract('([A-Za-z]+)\\.') #extracting Name initials\n",
    "\n",
    "\n",
    "\n",
    "X_test['Initial'].replace(['Mlle','Mme','Ms','Dr','Major','Lady','Countess',\\\n",
    "                        'Jonkheer','Col','Rev','Capt','Sir','Don'],['Miss',\\\n",
    "                        'Miss','Miss','Mr','Mr','Mrs','Mrs','Other','Other','Other','Mr','Mr','Mr'],inplace=True)\n",
    "\n",
    "\n",
    "X_test.loc[(X_test.Age.isnull()) & (X_test.Initial=='Mr'),'Age']= 33\n",
    "X_test.loc[(X_test.Age.isnull()) & (X_test.Initial=='Mrs'),'Age']=36\n",
    "X_test.loc[(X_test.Age.isnull()) & (X_test.Initial=='Master'),'Age']=5\n",
    "X_test.loc[(X_test.Age.isnull()) & (X_test.Initial=='Miss'),'Age']=22\n",
    "X_test.loc[(X_test.Age.isnull()) & (X_test.Initial=='Other'),'Age']=46\n",
    "\n",
    "X_test.drop(['Initial'], axis=1,inplace=True)\n",
    "\n",
    "test_original['Initial']=0\n",
    "for i in test_original:\n",
    "    test_original['Initial']=test_original.Name.str.extract('([A-Za-z]+)\\.') #extracting Name initials\n",
    "\n",
    "\n",
    "\n",
    "test_original['Initial'].replace(['Mlle','Mme','Ms','Dr','Major','Lady','Countess',\\\n",
    "                        'Jonkheer','Col','Rev','Capt','Sir','Don'],['Miss',\\\n",
    "                        'Miss','Miss','Mr','Mr','Mrs','Mrs','Other','Other','Other','Mr','Mr','Mr'],inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "test_original.loc[(test_original.Age.isnull()) & (test_original.Initial=='Mr'),'Age']= 33\n",
    "test_original.loc[(test_original.Age.isnull()) & (test_original.Initial=='Mrs'),'Age']=36\n",
    "test_original.loc[(test_original.Age.isnull()) & (test_original.Initial=='Master'),'Age']=5\n",
    "test_original.loc[(test_original.Age.isnull()) & (test_original.Initial=='Miss'),'Age']=22\n",
    "test_original.loc[(test_original.Age.isnull()) & (test_original.Initial=='Other'),'Age']=46\n",
    "\n",
    "test_original.drop(['Initial'], axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se elimina la varibale NAME porque no aporta\n",
    "X_train.drop(['Name'], axis=1,inplace=True)\n",
    "\n",
    "X_test.drop(['Name'], axis=1,inplace=True)\n",
    "\n",
    "test_original.drop(['Name'], axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se convierte la variable SEX a numerico, dado que para los modelos como texto no se puede utilizar, \n",
    "#y es una variable que aporta mucha informacion\n",
    "X_train['Sex'].replace(['male','female',''], [1,2,3],inplace=True)\n",
    "\n",
    "X_test['Sex'].replace(['male','female',''], [1,2,3],inplace=True)\n",
    "\n",
    "test_original['Sex'].replace(['male','female',''], [1,2,3],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se elimina la varibale Ticket porque no aporta\n",
    "X_train.drop(['Ticket'], axis=1,inplace=True)\n",
    "\n",
    "X_test.drop(['Ticket'], axis=1,inplace=True)\n",
    "\n",
    "test_original.drop(['Ticket'], axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Count por Embarked - Se genera un id para cada puerto y se reemplaza por las letras\n",
    "# 1 = C\n",
    "# 2 = S\n",
    "# 3 = Q\n",
    "# 4 = NA\n",
    "\n",
    "X_train['Embarked'].replace(['C','S','Q',''], [1,2,3,4],inplace=True)\n",
    "\n",
    "X_test['Embarked'].replace(['C','S','Q',''], [1,2,3,4],inplace=True)\n",
    "\n",
    "test_original['Embarked'].replace(['C','S','Q',''], [1,2,3,4],inplace=True)\n",
    "\n",
    "\n",
    "X_train.loc[(X_train.Embarked.isnull()) ,'Embarked']= 4\n",
    "X_test.loc[(X_test.Embarked.isnull()) ,'Embarked']= 4\n",
    "test_original.loc[(test_original.Embarked.isnull()) ,'Embarked']= 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape, X_test.shape,test_original.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_original.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODELOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se crea un dataframe para guardar los resultados de los distintos modelos\n",
    "results = pd.DataFrame()\n",
    "col_names =  ['Modelo','Acuracy']\n",
    "results  = pd.DataFrame(columns = col_names)\n",
    "#res = accuracy_score(y_test, y_pred)\n",
    "#results = results.append([{'Modelo':'Arbol - cluster lat-long-sup outliers-barrio_match - max depth = 6', 'Acuracy':res }], ignore_index=True)\n",
    "results.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ARBOL DE DECISION - ANALISIS DE MEJOR DEPTH\n",
    "MAX_DEPTH = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#se inicializan dos listas para poder generar sus metodos\n",
    "rmses_train = []\n",
    "rmses_test = []\n",
    "\n",
    "for max_depth in range(1,10, 1):\n",
    "    regressor = DecisionTreeRegressor(random_state=0, max_depth=max_depth)\n",
    "    regressor.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred_train = regressor.predict(X_train)\n",
    "    y_pred_train = pred_aceptable(y_pred_train)\n",
    "    \n",
    "    y_pred_test = regressor.predict(X_test)\n",
    "    y_pred_test = pred_aceptable(y_pred_test)\n",
    "    \n",
    "    rmse_train = accuracy_score(y_train, y_pred_train)\n",
    "    rmse_test = accuracy_score(y_test, y_pred_test)\n",
    "    \n",
    "    rmses_train.append(rmse_train)\n",
    "    rmses_test.append(rmse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "plt.plot(range(1,10, 1), rmses_train, label='Accuracy Training')\n",
    "plt.plot(range(1,10, 1), rmses_test, label='Accuracy Testing')\n",
    "plt.ylim((0, 1))\n",
    "plt.legend(loc=\"best\")\n",
    "plt.title(\"Accuracy Training vs Accuracy Testing para árboles de decisión\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor_Arb = DecisionTreeRegressor(random_state=0, max_depth=6)\n",
    "regressor_Arb.fit(X_train, y_train)\n",
    "y_pred = regressor_Arb.predict(X_test)\n",
    "y_pred = pred_aceptable(y_pred)\n",
    "rmse = accuracy_score(y_test, y_pred)\n",
    "print(np.round(rmse, 2))\n",
    "results = results.append([{'Modelo':'Arbol - max depth = 2', 'Acuracy':rmse }], ignore_index=True)\n",
    "results.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN -- Se analiza cual es el valor de vecinos optimo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmses_train = []\n",
    "rmses_test = []\n",
    "for nn in range(1,30, 1):\n",
    "    regressor = KNeighborsRegressor(n_neighbors=nn)\n",
    "    regressor.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred_train = regressor.predict(X_train)\n",
    "    y_pred_train = pred_aceptable(y_pred_train)\n",
    "    \n",
    "    y_pred_test = regressor.predict(X_test)\n",
    "    y_pred_test = pred_aceptable(y_pred_test)\n",
    "    \n",
    "    rmse_train = accuracy_score(y_train, y_pred_train)\n",
    "    rmse_test = accuracy_score(y_test, y_pred_test)\n",
    "    \n",
    "    rmses_train.append(rmse_train)\n",
    "    rmses_test.append(rmse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(1,30, 1), rmses_train, label='Acurracy Training')\n",
    "plt.plot(range(1,30, 1), rmses_test, label='Acurracy Testing')\n",
    "plt.ylim((0, 1))\n",
    "plt.legend(loc=\"best\")\n",
    "plt.title(\"Acurracy Training vs Acurracy Testing para KNN\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##KNN\n",
    "regressor = KNeighborsRegressor(n_neighbors=8)\n",
    "regressor.fit(X_train, y_train)\n",
    "y_pred = regressor.predict(X_test)\n",
    "y_pred = pred_aceptable(y_pred)\n",
    "rmse = accuracy_score(y_test, y_pred)\n",
    "print(np.round(rmse, 2))\n",
    "results = results.append([{'Modelo':'KNN - 8', 'Acuracy':rmse }], ignore_index=True)\n",
    "results.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LINEAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LINEAL\n",
    "regressor = linear_model.LinearRegression()\n",
    "regressor.fit(X_train, y_train)\n",
    "y_pred = regressor.predict(X_test)\n",
    "y_pred = pred_aceptable(y_pred)\n",
    "rmse = accuracy_score(y_test, y_pred)\n",
    "print(np.round(rmse, 2))\n",
    "results = results.append([{'Modelo':'Lineal', 'Acuracy':rmse }], ignore_index=True)\n",
    "results.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RIDGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = linear_model.Ridge(alpha=0.5)\n",
    "regressor.fit(X_train, y_train)\n",
    "y_pred = regressor.predict(X_test)\n",
    "y_pred = pred_aceptable(y_pred)\n",
    "rmse = accuracy_score(y_test, y_pred)\n",
    "print(np.round(rmse, 2))\n",
    "results = results.append([{'Modelo':'Ridge', 'Acuracy':rmse }], ignore_index=True)\n",
    "results.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LASSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = linear_model.LassoLars(alpha=.1)\n",
    "regressor.fit(X_train, y_train)\n",
    "y_pred = regressor.predict(X_test)\n",
    "y_pred = pred_aceptable(y_pred)\n",
    "rmse = accuracy_score(y_test, y_pred)\n",
    "print(np.round(rmse, 2))\n",
    "results = results.append([{'Modelo':'Lasso ', 'Acuracy':rmse }], ignore_index=True)\n",
    "results.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BayesianRidge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = linear_model.BayesianRidge()\n",
    "regressor.fit(X_train, y_train)\n",
    "y_pred = regressor.predict(X_test)\n",
    "y_pred = pred_aceptable(y_pred)\n",
    "rmse = accuracy_score(y_test, y_pred)\n",
    "print(np.round(rmse, 2))\n",
    "results = results.append([{'Modelo':'BayesianRidge', 'Acuracy':rmse }], ignore_index=True)\n",
    "results.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.sort_values(by='Acuracy', axis=0, ascending=False, inplace=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREDICCION PARA TEST ORIGINAL con el mejor modelo ARBOL CON PROFUNDIDAD DE 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtest_original = test_original.drop(['PassengerId'], axis=1)\n",
    "\n",
    "ID_test_original = test_original['PassengerId']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#regressor_Arb = DecisionTreeRegressor(random_state=0, max_depth=6)\n",
    "#regressor_Arb.fit(X_train, y_train)\n",
    "y_pred_final = regressor_Arb.predict(Xtest_original)\n",
    "y_pred_final = pred_aceptable(y_pred_final)\n",
    "\n",
    "\n",
    "y_pred_final =pd.DataFrame(y_pred_final,columns=[\"Survived\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out = pd.concat([ID_test_original,y_pred_final], axis=1 )\n",
    "df_out.to_csv(\"output/arbol_python.csv\",sep=\",\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SEGUNDO INTENTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analisis de outliers para Fare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(X_train.Fare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se eliminan los casos mayores a 300\n",
    "X_train = X_train[ (X_train.Fare < X_train.Fare.quantile(0.9))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.Fare.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.drop(['cluster'], axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se eliminan las filas en y_train que se eliminaron en X_train\n",
    "y_train = y_train.loc[X_train.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#se inicializan dos listas para poder generar sus metodos\n",
    "rmses_train = []\n",
    "rmses_test = []\n",
    "\n",
    "for max_depth in range(1,30, 1):\n",
    "    regressor = DecisionTreeRegressor(random_state=0, max_depth=max_depth)\n",
    "    regressor.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred_train = regressor.predict(X_train)\n",
    "    y_pred_train = pred_aceptable(y_pred_train)\n",
    "    \n",
    "    y_pred_test = regressor.predict(X_test)\n",
    "    y_pred_test = pred_aceptable(y_pred_test)\n",
    "    \n",
    "    rmse_train = accuracy_score(y_train, y_pred_train)\n",
    "    rmse_test = accuracy_score(y_test, y_pred_test)\n",
    "    \n",
    "    rmses_train.append(rmse_train)\n",
    "    rmses_test.append(rmse_test)\n",
    "    \n",
    "plt.plot(range(1,30, 1), rmses_train, label='Acurracy Training')\n",
    "plt.plot(range(1,30, 1), rmses_test, label='Acurracy Testing')\n",
    "plt.ylim((0, 1))\n",
    "plt.legend(loc=\"best\")\n",
    "plt.title(\"Acurracy Training vs Acurracy Testing para Arbol\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor_Arb = DecisionTreeRegressor(random_state=0, max_depth=8)\n",
    "regressor_Arb.fit(X_train, y_train)\n",
    "y_pred = regressor_Arb.predict(X_test)\n",
    "y_pred = pred_aceptable(y_pred)\n",
    "rmse = accuracy_score(y_test, y_pred)\n",
    "print(np.round(rmse, 2))\n",
    "results = results.append([{'Modelo':'Arbol - segundo intento -max depth = 8', 'Acuracy':rmse }], ignore_index=True)\n",
    "results.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmses_train = []\n",
    "rmses_test = []\n",
    "for nn in range(1,30, 1):\n",
    "    regressor = KNeighborsRegressor(n_neighbors=nn)\n",
    "    regressor.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred_train = regressor.predict(X_train)\n",
    "    y_pred_train = pred_aceptable(y_pred_train)\n",
    "    \n",
    "    y_pred_test = regressor.predict(X_test)\n",
    "    y_pred_test = pred_aceptable(y_pred_test)\n",
    "    \n",
    "    rmse_train = accuracy_score(y_train, y_pred_train)\n",
    "    rmse_test = accuracy_score(y_test, y_pred_test)\n",
    "    \n",
    "    rmses_train.append(rmse_train)\n",
    "    rmses_test.append(rmse_test)\n",
    "    \n",
    "plt.plot(range(1,30, 1), rmses_train, label='Acurracy Training')\n",
    "plt.plot(range(1,30, 1), rmses_test, label='Acurracy Testing')\n",
    "plt.ylim((0, 1))\n",
    "plt.legend(loc=\"best\")\n",
    "plt.title(\"Acurracy Training vs Acurracy Testing para KNN\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##KNN\n",
    "regressor = KNeighborsRegressor(n_neighbors=8)\n",
    "regressor.fit(X_train, y_train)\n",
    "y_pred = regressor.predict(X_test)\n",
    "y_pred = pred_aceptable(y_pred)\n",
    "rmse = accuracy_score(y_test, y_pred)\n",
    "print(np.round(rmse, 2))\n",
    "results = results.append([{'Modelo':'KNN - 8-seg intento', 'Acuracy':rmse }], ignore_index=True)\n",
    "results.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
